# meta developer: @modwini

__pip_deps__ = ["g4f"] # <-- Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐž! Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ð° Ð¿Ð°ÐºÐµÑ‚ 'g4f'

import asyncio
import random
import logging
import g4f 
from g4f.Provider import Liaobots, FreeGpt, Bing # ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð¾Ð², Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¸Ð· Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ g4f

from telethon import events
from telethon.tl.patched import Message
from .. import loader, utils

logger = logging.getLogger(__name__)

@loader.tds
class G4fPersonaMod(loader.Module):
    """
    ÐœÐ¾Ð´ÑƒÐ»ÑŒ Ð´Ð»Ñ Hikka, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð² Ñ‡Ð°Ñ‚Ðµ Ð¾Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸ AI-Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹
    Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ g4f (GPT4Free) Ð´Ð»Ñ Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ðº GPT-3.5/GPT-4.
    """

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "ai_model",
                "gpt-3.5-turbo", # Ð˜Ð»Ð¸ "gpt-4", "palm" Ð¸ Ñ‚.Ð´. Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ð¸ Ð² g4f
                lambda: self.strings("ai_model_h"),
                validator=loader.validators.String(),
            ),
            loader.ConfigValue(
                "ai_provider",
                "", # ÐžÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¸Ð»Ð¸ ÑƒÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ "Liaobots", "FreeGpt"
                lambda: self.strings("ai_provider_h"),
                validator=loader.validators.String(),
            ),
            loader.ConfigValue(
                "persona_name",
                "ÐºÑ€ÐµÐ¹Ðº",
                lambda: self.strings("persona_name_h"),
                validator=loader.validators.String(),
            ),
            loader.ConfigValue(
                "persona_instructions",
                (
                    "Ð¢Ñ‹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð² Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ñ Ð½Ð¸ÐºÐ½ÐµÐ¹Ð¼Ð¾Ð¼ '{persona_name}'. "
                    "Ð¢ÐµÐ±Ðµ 18 Ð»ÐµÑ‚. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÐ°Ðº 18-Ð»ÐµÑ‚Ð½Ð¸Ð¹ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ðµ Ð±ÑƒÐºÐ²Ñ‹. "
                    "Ð£Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð¹ ÑÐ²Ð¾Ð¹ Ð½Ð¸ÐºÐ½ÐµÐ¹Ð¼ Ð¸ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ñ‚ÐµÐ±Ñ Ð¾Ð± ÑÑ‚Ð¾Ð¼ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ ÑÐ¿Ñ€Ð¾ÑÑÑ‚. "
                    "Ð‘ÑƒÐ´ÑŒ ÐºÑ€Ð°Ñ‚Ð¾Ðº Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ð°Ñ…."
                ),
                lambda: self.strings("persona_instructions_h"),
                validator=loader.validators.String(),
            ),
            loader.ConfigValue(
                "history_limit",
                30,
                lambda: self.strings("history_limit_h"),
                validator=loader.validators.Integer(minimum=5, maximum=100),
            ),
            loader.ConfigValue(
                "min_delay",
                2,
                lambda: self.strings("min_delay_h"),
                validator=loader.validators.Integer(minimum=0, maximum=10),
            ),
            loader.ConfigValue(
                "max_delay",
                5,
                lambda: self.strings("max_delay_h"),
                validator=loader.validators.Integer(minimum=0, maximum=10),
            ),
            loader.ConfigValue(
                "ai_timeout",
                60,
                lambda: self.strings("ai_timeout_h"),
                validator=loader.validators.Integer(minimum=10, maximum=300),
            ),
        )
        self.active_chats = {}  # {chat_id: True/False} - Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ñ‡Ð°Ñ‚Ð¾Ð²

    async def client_ready(self, client, db):
        self.client = client
        self.db = db
        self.active_chats = self.db.get("G4fPersonaMod", "active_chats", {})

        # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð´Ð»Ñ Ð½Ð¾Ð²Ñ‹Ñ… Ð²Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
        self.client.add_event_handler(
            self.on_new_message,
            events.NewMessage(incoming=True, outgoing=False) # incoming=True, outgoing=False - Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÐ»ÑƒÑˆÐ°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‡ÑƒÐ¶Ð¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
        )
        
        # Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ g4f Ð´Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ¸, ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
        # g4f.debug.logging = True

    strings = {
        "name": "G4fPersona",
        "ai_model_h": "ÐœÐ¾Ð´ÐµÐ»ÑŒ AI Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'gpt-3.5-turbo', 'gpt-4'). ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐ¹Ñ‚Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ g4f.",
        "ai_provider_h": "ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾: Ð˜Ð¼Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð° g4f (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'Liaobots', 'FreeGpt', 'Bing'). ÐžÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð²Ñ‹Ð±Ð¾Ñ€Ð°. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ.",
        "persona_name_h": "Ð˜Ð¼Ñ, Ð¾Ñ‚ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ AI (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'ÐºÑ€ÐµÐ¹Ðº')",
        "persona_instructions_h": "Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ AI Ð¿Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°Ð¼. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ {persona_name} Ð´Ð»Ñ Ð¿Ð¾Ð´ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ Ð¸Ð¼ÐµÐ½Ð¸.",
        "history_limit_h": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° (Ð¾Ñ‚ 5 Ð´Ð¾ 100).",
        "min_delay_h": "ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "max_delay_h": "ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "ai_timeout_h": "Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ (Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…) Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº AI. Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ, ÐµÑÐ»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð¾Ð»Ð³Ð¸Ðµ.",
        "ii_on": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ G4fPersona Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ Ð² ÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ðµ. Ð¯ Ð±ÑƒÐ´Ñƒ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ ÐºÐ°Ðº {}.",
        "ii_off": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ G4fPersona Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½.",
        "ii_deleted": "```.ii``` (ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾)",
        "processing": "```Ð´ÑƒÐ¼Ð°ÑŽ...```",
        "error_provider": "âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð£ÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ '{}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½ÐµÐ´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÐµÐ½. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð° Ð¸Ð»Ð¸ Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿Ð¾Ð»Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð²Ñ‹Ð±Ð¾Ñ€Ð°.",
        "error_processing": "âŒ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {}",
        "error_timeout": "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI Ð·Ð° Ð¾Ñ‚Ð²ÐµÐ´ÐµÐ½Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ ({} ÑÐµÐº.). ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.",
        "not_text": "G4fPersona Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.",
        "not_supported": "âŒ Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ '{}' Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¼ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð¾Ð¼ '{}'. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ Ð¸Ð»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."
    }

    strings_ru = {
        "name": "G4fPersona",
        "ai_model_h": "ÐœÐ¾Ð´ÐµÐ»ÑŒ AI Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'gpt-3.5-turbo', 'gpt-4'). ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐ¹Ñ‚Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ g4f.",
        "ai_provider_h": "ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾: Ð˜Ð¼Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð° g4f (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'Liaobots', 'FreeGpt', 'Bing'). ÐžÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð²Ñ‹Ð±Ð¾Ñ€Ð°. Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ.",
        "persona_name_h": "Ð˜Ð¼Ñ, Ð¾Ñ‚ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ AI (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'ÐºÑ€ÐµÐ¹Ðº')",
        "persona_instructions_h": "Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ AI Ð¿Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°Ð¼. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ {persona_name} Ð´Ð»Ñ Ð¿Ð¾Ð´ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ Ð¸Ð¼ÐµÐ½Ð¸.",
        "history_limit_h": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° (Ð¾Ñ‚ 5 Ð´Ð¾ 100).",
        "min_delay_h": "ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "max_delay_h": "ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "ai_timeout_h": "Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ (Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…) Ð´Ð»Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº AI. Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ, ÐµÑÐ»Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð¾Ð»Ð³Ð¸Ðµ.",
        "ii_on": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ G4fPersona Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ Ð² ÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ðµ. Ð¯ Ð±ÑƒÐ´Ñƒ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ ÐºÐ°Ðº {}.",
        "ii_off": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ G4fPersona Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½.",
        "ii_deleted": "```.ii``` (ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾)",
        "processing": "```Ð´ÑƒÐ¼Ð°ÑŽ...```",
        "error_provider": "âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð£ÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ '{}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¸Ð»Ð¸ Ð½ÐµÐ´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÐµÐ½. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð° Ð¸Ð»Ð¸ Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿Ð¾Ð»Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð²Ñ‹Ð±Ð¾Ñ€Ð°.",
        "error_processing": "âŒ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {}",
        "error_timeout": "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI Ð·Ð° Ð¾Ñ‚Ð²ÐµÐ´ÐµÐ½Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ ({} ÑÐµÐº.). ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.",
        "not_text": "G4fPersona Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.",
        "not_supported": "âŒ Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ '{}' Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¼ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð¾Ð¼ '{}'. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€ Ð¸Ð»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ."
    }

    @loader.command("ii")
    async def iicmd(self, m: Message):
        """Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚/Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ñ€ÐµÐ¶Ð¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¾Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸ AI-Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹ Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ñ‡Ð°Ñ‚Ðµ."""
        chat_id = utils.get_chat_id(m)
        persona_name = self.config["persona_name"]

        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹ ÑÑ€Ð°Ð·Ñƒ
        await m.delete()
        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð¾Ð± ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ð¸
        await utils.answer(m, self.strings("ii_deleted"))

        if self.active_chats.get(chat_id, False):
            self.active_chats[chat_id] = False
            await utils.answer(m, self.strings("ii_off"))
        else:
            self.active_chats[chat_id] = True
            await utils.answer(m, self.strings("ii_on").format(persona_name))

        self.db.set("G4fPersonaMod", "active_chats", self.active_chats)

    async def on_new_message(self, event):
        m = event.message

        if not m.is_private and not m.is_group:
            return

        chat_id = utils.get_chat_id(m)
        if not self.active_chats.get(chat_id, False):
            return  # Ð ÐµÐ¶Ð¸Ð¼ Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½ Ð² ÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ðµ

        # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¾Ñ‚ ÑÐ°Ð¼Ð¾Ð³Ð¾ Ð±Ð¾Ñ‚Ð° (Ð²Ð°ÑˆÐµÐ³Ð¾ ÑŽÐ·ÐµÑ€Ð±Ð¾Ñ‚Ð° Hikka)
        me = await self.client.get_me()
        if m.sender_id == me.id:
            return

        if m.text and m.text.startswith(".ii"):
            return  # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ°Ð¼Ñƒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ .ii, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð·Ð±ÐµÐ¶Ð°Ñ‚ÑŒ Ð¿ÐµÑ‚Ð»Ð¸

        if not m.text:
            await utils.answer(m, self.strings("not_text"))
            return  # ÐžÑ‚Ð²ÐµÑ‡Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ

        persona_name = self.config["persona_name"]
        persona_instructions = self.config["persona_instructions"].format(persona_name=persona_name)
        history_limit = self.config["history_limit"]
        min_delay = self.config["min_delay"]
        max_delay = self.config["max_delay"]
        ai_model = self.config["ai_model"]
        ai_provider_name = self.config["ai_provider"]
        ai_timeout = self.config["ai_timeout"]

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¾Ð±ÑŠÐµÐºÑ‚ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð° g4f
        provider_obj = None
        if ai_provider_name:
            provider_obj = getattr(g4f.Provider, ai_provider_name, None)
            if not provider_obj:
                logger.error(f"Invalid g4f provider specified: {ai_provider_name}")
                await utils.answer(m, self.strings("error_provider").format(ai_provider_name))
                return
            # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÑƒ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð¾Ð¼ (Ð½Ðµ Ð²ÑÐµ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ñ‹ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹)
            # ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ: ÐÑ‚Ñ€Ð¸Ð±ÑƒÑ‚Ñ‹ 'supports_gpt_4' Ð¸ 'supports_gpt_35_turbo' Ð¼Ð¾Ð³ÑƒÑ‚ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ
            # Ñƒ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð¾Ð² Ð² g4f, ÑÑ‚Ð¾ Ð»Ð¸ÑˆÑŒ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸.
            # Ð›ÑƒÑ‡ÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ð¾Ð¿Ð¸Ñ€Ð°Ñ‚ÑŒÑÑ Ð½Ð° Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½ÑƒÑŽ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ g4f Ð¸Ð»Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ.
            if ai_model == "gpt-4" and not getattr(provider_obj, 'supports_gpt_4', False):
                 await utils.answer(m, self.strings("not_supported").format(ai_model, ai_provider_name))
                 return
            elif ai_model == "gpt-3.5-turbo" and not getattr(provider_obj, 'supports_gpt_35_turbo', False):
                 await utils.answer(m, self.strings("not_supported").format(ai_model, ai_provider_name))
                 return

        try:
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ñ‡Ð°Ñ‚Ð° Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ g4f (OpenAI roles)
            chat_messages = []
            me_id = me.id # ID Ð²Ð°ÑˆÐµÐ³Ð¾ ÑŽÐ·ÐµÑ€Ð±Ð¾Ñ‚Ð°

            # Fetch messages in reverse chronological order and build history
            messages_to_process = []
            async for msg in self.client.iter_messages(chat_id, limit=history_limit):
                if msg.text:
                    messages_to_process.append(msg)
            
            # Process messages from oldest to newest for chronological context
            for msg in reversed(messages_to_process):
                # If the message is from me, it's a "persona" (assistant) response
                # Otherwise, it's a "user" message
                role = "assistant" if msg.sender_id == me_id else "user"
                chat_messages.append({"role": role, "content": msg.text})
            
            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ AI-Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹
            messages_for_ai = [
                {"role": "system", "content": persona_instructions}
            ] + chat_messages

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
            messages_for_ai.append({"role": "user", "content": m.text})

            # Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°
            delay = random.uniform(min_delay, max_delay)
            await asyncio.sleep(delay)

            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ "Ð´ÑƒÐ¼Ð°ÑŽ..." ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
            thinking_message = await utils.answer(m, self.strings("processing"))

            full_response_text = ""
            try:
                # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð² g4f
                response_generator = g4f.ChatCompletion.create_async(
                    model=ai_model,
                    messages=messages_for_ai,
                    provider=provider_obj, # Ð‘ÑƒÐ´ÐµÑ‚ None, ÐµÑÐ»Ð¸ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½ Ð¸Ð»Ð¸ Ð½ÐµÐ´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÐµÐ½ (Ð°Ð²Ñ‚Ð¾Ð²Ñ‹Ð±Ð¾Ñ€)
                    stream=True, # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð°Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚ÑÐ¼
                    timeout=ai_timeout
                )
                
                # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚ÑÐ¼
                async for chunk in response_generator:
                    if chunk:
                        full_response_text += chunk
                        # ÐœÐ¾Ð¶Ð½Ð¾ Ñ‚ÑƒÑ‚ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ thinking_message, Ð½Ð¾ ÑÑ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð²Ñ‹Ð·Ð²Ð°Ñ‚ÑŒ Ñ„Ð»ÑƒÐ´-Ð»Ð¸Ð¼Ð¸Ñ‚Ñ‹.
                        # utils.answer ÑƒÐ¶Ðµ ÑÐ°Ð¼ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐµÑ‚, Ñ‚Ð°Ðº Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÐ¾Ð±ÐµÑ€ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚.
                        # Ð”Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ñ†ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð° Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸, Ð½ÑƒÐ¶Ð½Ð¾ Ð´Ð¾Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ.
                        pass 

                # Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ "Ð´ÑƒÐ¼Ð°ÑŽ..." Ð½Ð° Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI
                if full_response_text:
                    await utils.answer(thinking_message, full_response_text)
                else:
                    await utils.answer(thinking_message, self.strings("error_processing").format("ÐŸÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI."))

            except asyncio.TimeoutError:
                await utils.answer(thinking_message, self.strings("error_timeout").format(ai_timeout))
            except Exception as e:
                logger.error(f"Error getting response from g4f: {e}", exc_info=True)
                await utils.answer(thinking_message, self.strings("error_processing").format(e))

        except Exception as e:
            logger.error(f"Error in G4fPersonaMod listener: {e}", exc_info=True)
            await utils.answer(m, self.strings("error_processing").format(e))
