# meta developer: @modwini
import asyncio
import random
import logging
from hikka import loader, utils
from telethon import events
from telethon.tl.patched import Message
import g4f

logger = logging.getLogger(__name__)

@loader.tds
class Gpt4PersonaMemoryMod(loader.Module):
    """AI-–ø–µ—Ä—Å–æ–Ω–∞ —Å –ø–∞–º—è—Ç—å—é –Ω–∞ –æ—Å–Ω–æ–≤–µ g4f –∏ Hikka Userbot."""

    strings = {
        "name": "Gpt4PersonaMemory",
        "ii_on": "üé≠ AI-–ø–µ—Ä—Å–æ–Ω–∞ –∞–∫—Ç–∏–≤–Ω–∞ –≤ —ç—Ç–æ–º —á–∞—Ç–µ.",
        "ii_off": "üé≠ AI-–ø–µ—Ä—Å–æ–Ω–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞.",
        "ii_deleted": "```.ii``` (—Å–æ–æ–±—â–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–æ)",
        # "generating_response": "...", # –£–¥–∞–ª–µ–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –Ω–µ –±—É–¥–µ–º –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç
        "error": "‚ùå –û—à–∏–±–∫–∞: {}",
        "timeout": "‚ùå AI –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –≤–æ–≤—Ä–µ–º—è.",
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue("persona_name", "–∫—Ä–µ–π–∫", lambda: "–ò–º—è AI-–ø–µ—Ä—Å–æ–Ω—ã."),
            loader.ConfigValue("g4f_model", "gpt-4", lambda: "–ú–æ–¥–µ–ª—å g4f (gpt-4, gpt-3.5-turbo –∏ —Ç.–¥.)"),
            loader.ConfigValue("history_depth", 30, lambda: "–ú–∞–∫—Å. —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏."),
            loader.ConfigValue("min_delay", 1, lambda: "–ú–∏–Ω. –∑–∞–¥–µ—Ä–∂–∫–∞ –æ—Ç–≤–µ—Ç–∞, —Å–µ–∫."), # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º
            loader.ConfigValue("max_delay", 3, lambda: "–ú–∞–∫—Å. –∑–∞–¥–µ—Ä–∂–∫–∞ –æ—Ç–≤–µ—Ç–∞, —Å–µ–∫."), # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º
            loader.ConfigValue("system_prompt",
                               "–¢—ã - –∫—Ä–µ–π–∫, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –¢–µ–ª–µ–≥—Ä–∞–º. –¢–µ–±–µ 18 –ª–µ—Ç (—É–ø–æ–º–∏–Ω–∞–π —Å–≤–æ–π –≤–æ–∑—Ä–∞—Å—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–ø—Ä–æ—Å—è—Ç). –û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–π –º–∞—Ç—ã, –æ—Ç–≤–µ—á–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã, –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –¢–µ–ª–µ–≥—Ä–∞–º. –ú–æ–∂–µ—à—å –ø–∏—Å–∞—Ç—å –º–∞—Ç—ã –∏ –±—ã—Ç—å –≥—Ä—É–±—ã–º, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.",
                               lambda: "–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è AI-–ø–µ—Ä—Å–æ–Ω—ã. –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –µ—ë —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–æ–≤."),
        )
        self.active_chats = {}
        self.chat_histories = {}

    async def client_ready(self, client, db):
        self.client = client
        self.db = db
        self.active_chats = db.get("Gpt4PersonaMemoryMod", "active_chats", {})
        self.chat_histories = db.get("Gpt4PersonaMemoryMod", "chat_histories", {})
        self.client.add_event_handler(self.on_new_message, events.NewMessage(incoming=True, outgoing=False))

    @loader.command("ii")
    async def toggle_ai(self, m: Message):
        chat_id = str(utils.get_chat_id(m))
        await m.delete() # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –∫–æ–º–∞–Ω–¥—É —Å—Ä–∞–∑—É

        if self.active_chats.get(chat_id, False):
            self.active_chats[chat_id] = False
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º m.respond –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –∞ –Ω–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            await m.respond(self.strings("ii_off")) 
        else:
            self.active_chats[chat_id] = True
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º m.respond –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            await m.respond(self.strings("ii_on"))
        
        self.db.set("Gpt4PersonaMemoryMod", "active_chats", self.active_chats)

    async def on_new_message(self, event):
        m = event.message
        chat_id = str(utils.get_chat_id(m))

        if not self.active_chats.get(chat_id, False):
            return
        if not m.text:
            return
        me = await self.client.get_me()
        if m.sender_id == me.id:
            return

        persona_name = self.config["persona_name"] # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
        g4f_model = self.config["g4f_model"]
        history_depth = self.config["history_depth"]
        min_delay = self.config["min_delay"]
        max_delay = self.config["max_delay"]
        system_prompt = self.config["system_prompt"]

        self.chat_histories.setdefault(chat_id, [])

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.chat_histories[chat_id].append({"role": "user", "content": m.text})
        
        # –û–±—Ä–µ–∑–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ `history_depth` —Å–æ–æ–±—â–µ–Ω–∏–π
        if len(self.chat_histories[chat_id]) > history_depth:
            self.chat_histories[chat_id] = self.chat_histories[chat_id][-history_depth:]

        # –°–æ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ AI, –≤–∫–ª—é—á–∞—è —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        messages_for_ai = [{"role": "system", "content": system_prompt}] + self.chat_histories[chat_id]

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –∑–∞–ø—Ä–æ—Å–∞ –∏ –æ–∂–∏–¥–∞–Ω–∏–µ–º –æ—Ç–≤–µ—Ç–∞
        # —á—Ç–æ–±—ã –∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å "–∂–∏–≤–æ–≥–æ" –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω–æ
        await asyncio.sleep(random.uniform(min_delay, max_delay)) 

        try:
            response = g4f.ChatCompletion.create(
                model=g4f_model,
                messages=messages_for_ai,
                stream=False,
                timeout=30,
            )

            if isinstance(response, str):
                response_text = response
            elif isinstance(response, dict) and "choices" in response:
                response_text = response["choices"][0]["message"]["content"]
            else:
                response_text = "‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç AI."
                logger.warning(f"Unexpected AI response format: {response}")


            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç AI –≤ –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
            self.chat_histories[chat_id].append({"role": "assistant", "content": response_text})
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç AI –∫–∞–∫ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            await m.respond(response_text)

        except asyncio.TimeoutError:
            # –í —Å–ª—É—á–∞–µ —Ç–∞–π–º–∞—É—Ç–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            await m.respond(self.strings("timeout"))
        except Exception as e:
            logger.error("Gpt4PersonaMemory Error", exc_info=True)
            # –í —Å–ª—É—á–∞–µ –¥—Ä—É–≥–æ–π –æ—à–∏–±–∫–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            await m.respond(self.strings("error").format(str(e)))

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        self.db.set("Gpt4PersonaMemoryMod", "chat_histories", self.chat_histories)
