# meta developer: @modwini

import asyncio
import random
import logging
from hikka import loader, utils
from telethon import events
from telethon.tl.patched import Message

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸ g4f
import g4f

# ÐžÐ¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾: Ñ€Ð°ÑÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð´Ð»Ñ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ g4f
# g4f.debug.logging = True
# g4f.check_version = False # ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ Ð²ÐµÑ€ÑÐ¸Ð¸ g4f

logger = logging.getLogger(__name__)

@loader.tds
class Gpt4PersonaMod(loader.Module): # ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ° Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¾ Ð´Ð»Ñ ÑÑÐ½Ð¾ÑÑ‚Ð¸
    """
    ÐœÐ¾Ð´ÑƒÐ»ÑŒ Ð´Ð»Ñ Hikka, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð² Ñ‡Ð°Ñ‚Ðµ Ð¾Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸ AI-Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹
    Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ GPT4Free (g4f).
    """

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "persona_name",
                "ÐºÑ€ÐµÐ¹Ðº",
                lambda: self.strings("persona_name_h"),
                validator=loader.validators.String(),
            ),
            loader.ConfigValue(
                "history_limit",
                30,
                lambda: self.strings("history_limit_h"),
                validator=loader.validators.Integer(minimum=5, maximum=100),
            ),
            loader.ConfigValue(
                "min_delay",
                2,
                lambda: self.strings("min_delay_h"),
                validator=loader.validators.Integer(minimum=0, maximum=10),
            ),
            loader.ConfigValue(
                "max_delay",
                5,
                lambda: self.strings("max_delay_h"),
                validator=loader.validators.Integer(minimum=0, maximum=10),
            ),
            loader.ConfigValue(
                "ai_model",
                "gpt-4", # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ 'gpt-4' ÐºÐ°Ðº Ð·Ð°Ð¿Ñ€Ð¾ÑˆÐµÐ½Ð¾
                lambda: self.strings("ai_model_h"),
                validator=loader.validators.String(),
            ),
            loader.ConfigValue(
                "ai_timeout",
                45, # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ñ‹Ðµ API Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¼Ð¸
                lambda: self.strings("ai_timeout_h"),
                validator=loader.validators.Integer(minimum=10, maximum=120),
            ),
        )
        self.active_chats = {}  # {chat_id: True/False} - Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ñ‡Ð°Ñ‚Ð¾Ð²

    async def client_ready(self, client, db):
        self.client = client
        self.db = db
        self.active_chats = self.db.get("Gpt4PersonaMod", "active_chats", {})

        # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð´Ð»Ñ Ð½Ð¾Ð²Ñ‹Ñ… Ð²Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
        self.client.add_event_handler(
            self.on_new_message,
            events.NewMessage(incoming=True, outgoing=False) # Ð¡Ð»ÑƒÑˆÐ°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‡ÑƒÐ¶Ð¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
        )

    strings = {
        "name": "GPT4Persona", # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð¾Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÑƒÐ»Ñ
        "persona_name_h": "Ð˜Ð¼Ñ, Ð¾Ñ‚ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ AI (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'ÐºÑ€ÐµÐ¹Ðº')",
        "history_limit_h": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° (Ð¾Ñ‚ 5 Ð´Ð¾ 100).",
        "min_delay_h": "ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "max_delay_h": "ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "ai_model_h": "ÐœÐ¾Ð´ÐµÐ»ÑŒ AI Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'gpt-4', 'gpt-3.5-turbo', 'default'). Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ g4f Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ ÐµÐµ.",
        "ai_timeout_h": "Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "ii_on": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ GPT4Persona Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ Ð² ÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ðµ. Ð¯ Ð±ÑƒÐ´Ñƒ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ ÐºÐ°Ðº {}.",
        "ii_off": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ GPT4Persona Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½.",
        "ii_deleted": "```.ii``` (ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾)",
        "processing": "```Ð´ÑƒÐ¼Ð°ÑŽ...```",
        "error_processing": "âŒ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {}",
        "error_timeout": "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI Ð·Ð° Ð¾Ñ‚Ð²ÐµÐ´ÐµÐ½Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.",
        "not_text": "GPT4Persona Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.",
        "g4f_not_working": "âŒ G4F Error: ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI. Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð½ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ñ… Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð¾Ð² Ð´Ð»Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ({}) Ð¸Ð»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð¾Ð¼ Ðº free-API. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð»Ð¸ Ð¿Ð¾Ð·Ð¶Ðµ.",
        "_cmd_doc_ii": "Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚/Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ñ€ÐµÐ¶Ð¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¾Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸ AI-Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹ Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ñ‡Ð°Ñ‚Ðµ."
    }

    strings_ru = { # Ð ÑƒÑÑÐºÐ¸Ð¹ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ ÑÑ‚Ñ€Ð¾Ðº
        "name": "GPT4Persona",
        "persona_name_h": "Ð˜Ð¼Ñ, Ð¾Ñ‚ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ AI (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'ÐºÑ€ÐµÐ¹Ðº')",
        "history_limit_h": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° (Ð¾Ñ‚ 5 Ð´Ð¾ 100).",
        "min_delay_h": "ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "max_delay_h": "ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼ AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "ai_model_h": "ÐœÐ¾Ð´ÐµÐ»ÑŒ AI Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'gpt-4', 'gpt-3.5-turbo', 'default'). Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ g4f Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ ÐµÐµ.",
        "ai_timeout_h": "Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° AI Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ….",
        "ii_on": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ GPT4Persona Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ Ð² ÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ðµ. Ð¯ Ð±ÑƒÐ´Ñƒ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ ÐºÐ°Ðº {}.",
        "ii_off": "ðŸŽ­ Ð ÐµÐ¶Ð¸Ð¼ GPT4Persona Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½.",
        "ii_deleted": "```.ii``` (ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾)",
        "processing": "```Ð´ÑƒÐ¼Ð°ÑŽ...```",
        "error_processing": "âŒ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {}",
        "error_timeout": "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI Ð·Ð° Ð¾Ñ‚Ð²ÐµÐ´ÐµÐ½Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.",
        "not_text": "GPT4Persona Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.",
        "g4f_not_working": "âŒ G4F Error: ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI. Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð½ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ñ… Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð¾Ð² Ð´Ð»Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ({}) Ð¸Ð»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð¾Ð¼ Ðº free-API. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð»Ð¸ Ð¿Ð¾Ð·Ð¶Ðµ.",
        "_cmd_doc_ii": "Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚/Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ñ€ÐµÐ¶Ð¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¾Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸ AI-Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹ Ð² Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¼ Ñ‡Ð°Ñ‚Ðµ."
    }

    @loader.command("ii")
    async def iicmd(self, m: Message):
        """Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚/Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ñ€ÐµÐ¶Ð¸Ð¼ AI-Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹ Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ñ‡Ð°Ñ‚Ð°."""
        chat_id = utils.get_chat_id(m)
        persona_name = self.config["persona_name"]
        
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð½Ð¾Ð²Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
        is_active_now = not self.active_chats.get(chat_id, False)

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
        self.active_chats[chat_id] = is_active_now
        self.db.set("Gpt4PersonaMod", "active_chats", self.active_chats)

        # Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ð¾Ð½Ð¾ "ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾",
        # Ð·Ð°Ñ‚ÐµÐ¼ ÑƒÐ´Ð°Ð»ÑÐµÐ¼ ÐµÐ³Ð¾ Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð·Ð±ÐµÐ¶Ð°Ñ‚ÑŒ MessageIdInvalidError.
        try:
            await m.edit(self.strings("ii_deleted"))
            await asyncio.sleep(1) # ÐšÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÐ²Ð¸Ð´ÐµÐ» ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
            await m.delete()
        except Exception as e:
            logger.warning(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ñ‚Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ/ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹: {e}")
            # Ð•ÑÐ»Ð¸ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ/ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ, Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑÐ½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ

        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑÐ½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ ÐºÐ°Ðº Ð½Ð¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð² Ñ‡Ð°Ñ‚
        status_message = self.strings("ii_on").format(persona_name) if is_active_now else self.strings("ii_off")
        await self.client.send_message(chat_id, status_message)


    async def on_new_message(self, event):
        m = event.message # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¾Ð±ÑŠÐµÐºÑ‚ Message Ð¸Ð· event

        # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð½Ðµ Ð¸Ð· Ð¿Ñ€Ð¸Ð²Ð°Ñ‚Ð½Ñ‹Ñ… Ñ‡Ð°Ñ‚Ð¾Ð² Ð¸Ð»Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿
        if not m.is_private and not m.is_group:
            return

        chat_id = utils.get_chat_id(m)
        # Ð•ÑÐ»Ð¸ Ñ€ÐµÐ¶Ð¸Ð¼ Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½ Ð² ÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ðµ, Ð²Ñ‹Ñ…Ð¾Ð´Ð¸Ð¼
        if not self.active_chats.get(chat_id, False):
            return

        # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¾Ñ‚ ÑÐ°Ð¼Ð¾Ð³Ð¾ ÑŽÐ·ÐµÑ€Ð±Ð¾Ñ‚Ð° (Ð²Ð»Ð°Ð´ÐµÐ»ÑŒÑ†Ð°)
        me = await self.client.get_me()
        if m.sender_id == me.id:
            return

        # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ°Ð¼Ñƒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ .ii, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð·Ð±ÐµÐ¶Ð°Ñ‚ÑŒ Ð±ÐµÑÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾Ð³Ð¾ Ñ†Ð¸ÐºÐ»Ð°
        if m.text and m.text.lower().startswith(".ii"):
            return

        # ÐžÑ‚Ð²ÐµÑ‡Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
        if not m.text:
            await m.reply(self.strings("not_text"))
            return

        persona_name = self.config["persona_name"]
        history_limit = self.config["history_limit"]
        min_delay = self.config["min_delay"]
        max_delay = self.config["max_delay"]
        ai_model = self.config["ai_model"]
        ai_timeout = self.config["ai_timeout"]

        try:
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ñ‡Ð°Ñ‚Ð° Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
            history_messages = []
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ iter_messages Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð¸Ð· Ñ‡Ð°Ñ‚Ð°
            async for msg_hist in self.client.iter_messages(chat_id, limit=history_limit):
                if msg_hist.text:
                    sender = await msg_hist.get_sender() # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÐµÐ»Ðµ
                    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¸Ð¼Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÐµÐ»Ñ Ð´Ð»Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸
                    sender_name = persona_name if sender and sender.id == me.id else (sender.first_name or sender.username or f"ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ_{msg_hist.sender_id}")
                    history_messages.append(f"{sender_name}: {msg_hist.text}")
            
            # ÐŸÐµÑ€ÐµÐ²Ð¾Ñ€Ð°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÑ‚Ð°Ñ€Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð±Ñ‹Ð»Ð¸ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ (Ñ…Ñ€Ð¾Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº)
            history_string = "\n".join(reversed(history_messages))

            # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ AI Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ persona Ð¸ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
            prompt_content = (
                f"Ð¢Ñ‹ â€” Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Telegram Ñ Ð½Ð¸ÐºÐ½ÐµÐ¹Ð¼Ð¾Ð¼ {persona_name}. "
                f"Ð¢Ð²Ð¾Ð¹ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚ â€” 18 Ð»ÐµÑ‚, Ð¸ Ñ‚Ñ‹ Ð¾Ð±Ñ‰Ð°ÐµÑˆÑŒÑÑ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼Ð¸. "
                f"ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÑ‚Ñ€Ð¾Ñ‡Ð½Ñ‹Ðµ Ð±ÑƒÐºÐ²Ñ‹, ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾ Ð´Ð»Ñ Ð½ÐµÐ¿Ñ€Ð¸Ð½ÑƒÐ¶Ð´ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ. "
                f"Ð£Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð¹ ÑÐ²Ð¾Ð¹ Ð½Ð¸ÐºÐ½ÐµÐ¹Ð¼ Ð¸Ð»Ð¸ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ñ‚ÐµÐ±Ñ Ð¾Ð± ÑÑ‚Ð¾Ð¼ Ð¿Ñ€ÑÐ¼Ð¾ ÑÐ¿Ñ€Ð¾ÑÑÑ‚. "
                f"Ð’Ð¾Ñ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°:\n\n{history_string}\n\n"
                f"Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ: {m.text}"
            )

            # Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚Ð°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð¼Ð¸Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ "Ð´ÑƒÐ¼Ð°ÑŽÑ‰ÐµÐ³Ð¾" Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°
            delay = random.uniform(min_delay, max_delay)
            await asyncio.sleep(delay)

            # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ "Ð´ÑƒÐ¼Ð°ÑŽ..." Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÐµÐ³Ð¾ ÑÑÑ‹Ð»ÐºÑƒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð¾Ñ‚Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
            thinking_message = await m.reply(self.strings("processing"))

            try:
                # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ g4f.ChatCompletion.create
                # g4f Ð¾Ð¶Ð¸Ð´Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÐ»Ð¾Ð²Ð°Ñ€ÐµÐ¹ Ñ 'role' Ð¸ 'content'
                g4f_messages = [{"role": "user", "content": prompt_content}]

                # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð²Ñ‹Ð·Ð¾Ð² g4f API
                full_response_text = ""
                response_generator = g4f.ChatCompletion.create(
                    model=ai_model, # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ AI, ÑƒÐºÐ°Ð·Ð°Ð½Ð½ÑƒÑŽ Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 'gpt-4')
                    messages=g4f_messages,
                    stream=True, # Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²ÑƒÑŽ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‡Ñƒ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¾Ð³Ð¾ Ð¾Ð¿Ñ‹Ñ‚Ð°
                    timeout=ai_timeout, # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð¸Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
                )

                # ÐŸÐ¾Ñ‚Ð¾ÐºÐ¾Ð²Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾ Ð² Telegram, Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÑ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ "Ð´ÑƒÐ¼Ð°ÑŽ..."
                last_edited_text = ""
                # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
                async for message_chunk in response_generator:
                    if message_chunk and message_chunk != "[DONE]": # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸ ÑÐ¸Ð³Ð½Ð°Ð» [DONE]
                        full_response_text += message_chunk
                        # Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ð¸Ñ‡ÐµÑÐºÐ¸ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°
                        # (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, ÐºÐ°Ð¶Ð´Ñ‹Ðµ 50 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð¸Ð»Ð¸ ÐµÑÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‡ÐµÐ½ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹)
                        if len(full_response_text) - len(last_edited_text) > 50 or len(full_response_text) < 20: 
                            try:
                                await thinking_message.edit(full_response_text)
                                last_edited_text = full_response_text
                            except Exception as edit_e:
                                logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ ÑÑ‚Ñ€Ð¸Ð¼Ð¸Ð½Ð³Ð°: {edit_e}")
                                # Ð•ÑÐ»Ð¸ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ, Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð½Ð°ÐºÐ°Ð¿Ð»Ð¸Ð²Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¸ Ð»Ð¸ Ð¼Ñ‹ Ñ…Ð¾Ñ‚ÑŒ ÐºÐ°ÐºÐ¾Ð¹-Ñ‚Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚
                if not full_response_text.strip():
                    raise ValueError(self.strings("g4f_not_working").format(ai_model))

                # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ñ Ð¿Ð¾Ð»Ð½Ñ‹Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð¼
                await thinking_message.edit(full_response_text)

            except asyncio.TimeoutError:
                # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð°
                await thinking_message.edit(self.strings("error_timeout"))
            except Exception as e:
                # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº, ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ñ‹Ñ… Ð´Ð»Ñ g4f Ð¸Ð»Ð¸ Ð¾Ð±Ñ‰Ð¸Ñ…
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ g4f: {e}", exc_info=True)
                if "Model not found" in str(e) or "No provider" in str(e) or "Rate limit" in str(e) or "Failed to connect" in str(e):
                    # Ð‘Ð¾Ð»ÐµÐµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ, ÐµÑÐ»Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ñ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°Ð¼Ð¸ g4f
                    error_message_to_send = self.strings("g4f_not_working").format(ai_model)
                else:
                    error_message_to_send = self.strings("error_processing").format(e)
                await thinking_message.edit(error_message_to_send)

        except Exception as e:
            # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº, Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐµÐ´ÑˆÐ¸Ñ… Ð²Ð½Ðµ Ð±Ð»Ð¾ÐºÐ° Ð²Ñ‹Ð·Ð¾Ð²Ð° g4f (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸)
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»Ðµ Gpt4PersonaMod (Ð²Ð½ÐµÑˆÐ½Ð¸Ð¹ Ð±Ð»Ð¾Ðº): {e}", exc_info=True)
            try:
                await m.reply(self.strings("error_processing").format(e))
            except Exception as reply_e:
                logger.error(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹: {reply_e}", exc_info=True)
